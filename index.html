<!DOCTYPE HTML>
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

  <title>Xianpeng Liu</title>
  
  <meta name="author" content="Xianpeng Liu">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <link rel="stylesheet" type="text/css" href="stylesheet.css">
	<link rel="icon" href="data:image/svg+xml,<svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22><text y=%22.9em%22 font-size=%2290%22>üåê</text></svg>">
</head>

<body>
  <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr style="padding:0px">
      <td style="padding:0px">
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr style="padding:0px">
            <td style="padding:2.5%;width:63%;vertical-align:middle">
              <p style="text-align:center">
                <name>Xianpeng Liu</name>
              </p>
              <p style="font-size:16px">I received my Ph.D. degree in Electrical Engineering from North Carolina State University (NCSU), 
		advised by <a href="https://ece.ncsu.edu/people/twu19/" style="font-size:16px">Prof. Tianfu Wu</a>.</p>
              <p style="text-align:center">
                <a href="https://github.com/Xianpeng919">Github</a> &nbsp/&nbsp
                <a href="https://www.linkedin.com/in/xianpeng-liu-1bb109155/">LinkedIn</a> &nbsp/&nbsp
                <a href="https://scholar.google.com/citations?user=t1Vdm4wAAAAJ&hl=en">Google Scholar</a> &nbsp/&nbsp
                <a href="data/xianpeng_cv.pdf">Resume</a>
              </p>
              <p style="font-size:16px">
                Email: xliu59 [at] ncsu.edu
              </p>
            </td>
            <td style="padding:2.5%;width:40%;max-width:40%">
              <a href="images/xianpeng_photo.jpg"><img style="width:100%;max-width:100%" alt="profile photo" src="images/xianpeng_photo.jpg" class="hoverZoomLink"></a>
            </td>
          </tr>
        </tbody></table>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>News</heading>
              <p>
                <strong>2024-02</strong> &nbsp;&nbsp;&nbsp;&nbsp; One <a href="">paper</a> was accepted by CVPR 2024.
              </p>
              <p>
                <strong>2023-12</strong> &nbsp;&nbsp;&nbsp;&nbsp; I defended my Ph.D. dissertation.
              </p>
              <p>
                <strong>2023-07</strong> &nbsp;&nbsp;&nbsp;&nbsp; One <a href="https://arxiv.org/pdf/2304.01289.pdf">paper</a> was accepted by ICCV 2023.
              </p>
              <p>
                <strong>2023-05</strong> &nbsp;&nbsp;&nbsp;&nbsp; I passed my oral exam and proposal.
              </p>
              <p>
                <strong>2023-02</strong> &nbsp;&nbsp;&nbsp;&nbsp; One <a href="https://zczcwh.github.io/potter_page/">paper</a> was accepted by CVPR 2023.
              </p>
              <p>
                <strong>2022-05</strong> &nbsp;&nbsp;&nbsp;&nbsp; I started my research internship at  <a href="https://www.innopeaktech.com/">Innopeak Tech</a>.
              </p>

              <p>
                <strong>2022-01</strong> &nbsp;&nbsp;&nbsp;&nbsp; One <a href="https://arxiv.org/pdf/2112.04628.pdf">paper</a> was accepted by AAAI 2022.
              </p>
            </td>
          </tr>
        </tbody></table>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>Research</heading>
              <p>
                I have a broad interest in 2D and 3D computer vision. My current research focuses on 3D Object Detection, 3D Reconstruction, Human Pose Estimation, etc.
                Below is a <strong>selected</strong> list of my works. Full publication can be found at my google scholar page.
              </p>
            </td>
          </tr>
        </tbody></table>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>

          <tr onmouseout="mira_stop()" onmouseover="mira_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <img src='images/mvacon.png' width="160">
              </div>
              <script type="text/javascript">
                function mira_start() {
                  document.getElementById('mira_image').style.opacity = "1";
                }

                function mira_stop() {
                  document.getElementById('mira_image').style.opacity = "0";
                }
                mira_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <papertitle>Multi-View Attentive Contextualization for Multi-View 3D Object Detection.</papertitle>
              <br>
              <strong>Xianpeng Liu</strong>,
	      Ce Zheng,
	      Ming Qian,
			Nan Xue,
	      Chen Chen,
		  Zhebin Zhang,
		  Chen Li,
              Tianfu Wu.
              <br>
              <em>IEEE/CVF Conference on Computer Vision and Pattern Recognition (<strong>CVPR</strong>)</em>, 2024
              <br>
              <a href="">Paper</a> &nbsp/&nbsp
              <a href="https://xianpeng919.github.io/mvacon/">Project Page</a>
              <p></p>
              <p>
                A simple yet effective method for improving 2D-to-3D feature lifting in query-based multi-view 3D (MV3D) object detection.
              </p>
            </td>
          </tr>


          <tr onmouseout="mira_stop()" onmouseover="mira_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <img src='images/monoxiver-iccv23.png' width="160">
              </div>
              <script type="text/javascript">
                function mira_start() {
                  document.getElementById('mira_image').style.opacity = "1";
                }

                function mira_stop() {
                  document.getElementById('mira_image').style.opacity = "0";
                }
                mira_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <papertitle>Monocular 3D Object Detection with Bounding Box Denoising in 3D by Perceiver.</papertitle>
              <br>
              <strong>Xianpeng Liu</strong>,
	      Ce Zheng,
	      Kelvin Cheng,
              Nan Xue,
	      Guo-Jun Qi,
              Tianfu Wu.
              <br>
              <em>IEEE/CVF International Conference on Computer Vision (<strong>ICCV</strong>)</em>, 2023
              <br>
              <a href="https://arxiv.org/abs/2304.01289">Paper</a> &nbsp/&nbsp
              <a href="https://xianpeng919.github.io/monoxiver/">Project Page</a>
              <p></p>
              <p>
                A monocular 3D object detection method with a novel 3D space top-down bounding box denoising paradigm.
              </p>
            </td>
          </tr>
				
          <tr onmouseout="mira_stop()" onmouseover="mira_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <!-- <div class="two" id='mira_image'> -->
                  <!-- <img src='images/POTTER.JPG' width="160"></div> -->
                <img src='images/potter.gif' width="160">
              </div>
              <script type="text/javascript">
                function mira_start() {
                  document.getElementById('mira_image').style.opacity = "1";
                }

                function mira_stop() {
                  document.getElementById('mira_image').style.opacity = "0";
                }
                mira_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <papertitle>POTTER: Pooling Attention Transformer for Efficient Human Mesh Recovery</papertitle>
              <br>
              Ce Zheng,
              <strong>Xianpeng Liu</strong>,
              Guo-Jun Qi,
              Chen Chen.
              <br>
              <em>IEEE/CVF Conference on Computer Vision and Pattern Recognition (<strong>CVPR</strong>)</em>, 2023
              <br>
              <a href="https://arxiv.org/pdf/2303.13357.pdf">Paper</a> &nbsp/&nbsp
              <a href="https://zczcwh.github.io/potter_page/">Project page</a>
              <p></p>
              <p>
                A lightweight pure transformer architecture named POoling aTtention TransformER (POTTER) for the HMR task from single images.
              </p>
            </td>
          </tr>

          <tr onmouseout="mira_stop()" onmouseover="mira_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <!-- <div class="two" id='mira_image'> -->
                  <!-- <img src='images/POTTER.JPG' width="160"></div> -->
                <img src='images/monocon-aaai22.png' width="160">
              </div>
              <script type="text/javascript">
                function mira_start() {
                  document.getElementById('mira_image').style.opacity = "1";
                }

                function mira_stop() {
                  document.getElementById('mira_image').style.opacity = "0";
                }
                mira_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <papertitle>Learning Auxiliary Monocular Contexts Helps Monocular 3D Object Detection.</papertitle>
              <br>
              <strong>Xianpeng Liu</strong>,
              Nan Xue,
              Tianfu Wu.
              <br>
              <em>Proceedings of the AAAI Conference on Artificial Intelligence (<strong>AAAI</strong>)</em>, 2022
              <br>
              <a href="https://arxiv.org/abs/2112.04628">Paper</a> &nbsp/&nbsp
              <a href="https://github.com/Xianpeng919/MonoCon">Code</a>
              <p></p>
              <p>
                Leverage Monocular Contexts (MonoCon) to achieve rapid and precise 3D object detection from a single image.
              </p>
            </td>
          </tr>

          <tr onmouseout="mira_stop()" onmouseover="mira_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <!-- <div class="two" id='mira_image'> -->
                  <!-- <img src='images/POTTER.JPG' width="160"></div> -->
                <img src='images/crowdsourcing.png' width="160">
              </div>
              <script type="text/javascript">
                function mira_start() {
                  document.getElementById('mira_image').style.opacity = "1";
                }

                function mira_stop() {
                  document.getElementById('mira_image').style.opacity = "0";
                }
                mira_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <papertitle>Toward Effective Automated Content Analysis via Crowdsourcing.</papertitle>
              <br>
              Jiele Wu,
              Chau-Wai Wong,
              Xinyan Zhao,
              <strong>Xianpeng Liu</strong>.
              <br>
              <em>IEEE International Conference on Multimedia and Expo (<strong>ICME</strong>)</em>, 2021
              <br>
              <a href="https://store.computer.org/csdl/proceedings-article/icme/2021/09428220/1uilvjGCl1u">Paper</a>
              <p></p>
              <p>
                Design a quality-aware semantic data annotation system to achieve high annotation quality for crowdsourcing.
              </p>
            </td>
          </tr>

          <tr onmouseout="mira_stop()" onmouseover="mira_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <!-- <div class="two" id='mira_image'> -->
                  <!-- <img src='images/POTTER.JPG' width="160"></div> -->
                <img src='images/wetting_project.png' width="160">
              </div>
              <script type="text/javascript">
                function mira_start() {
                  document.getElementById('mira_image').style.opacity = "1";
                }

                function mira_stop() {
                  document.getElementById('mira_image').style.opacity = "0";
                }
                mira_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <papertitle>Video-Based Wetting Detection For Blended Fabrics.</papertitle>
              <br>
              <strong>Xianpeng Liu</strong>,
              Chau-Wai Wong.
              <br>
              <em>Asilomar Conference on Signals, Systems, and Computers</em>, 2019
              <br>
              <a href="https://ieeexplore.ieee.org/document/9048999">Paper</a> &nbsp/&nbsp
              <a href="data/2019_asilomar_wick_poster.pdf">Poster</a>
              <p></p>
              <p>
                Perform Likelihood-ratio test to achieve precise wetting detection from videos.
              </p>
            </td>
          </tr>


        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20"><tbody>
          <tr>
            <td>
              <heading>Service</heading>
            </td>
          </tr>
        </tbody></table>
        <table width="100%" align="center" border="0" cellpadding="20"><tbody>
					
          <tr>
            <td style="padding:16px;width:25%;vertical-align:middle"><img src="images/cvf.jpg"></td>
            <td width="75%" valign="center">
              Journal Reviewer: Image and Vision Computing, Neurocomputing, Neural Networks, IEEE/CAA Journal of Automatica Sinica, Frontiers of Computer Science
              <br>
              Conference Reviewer: CVPR, ICCV, ECCV
            </td>
          </tr>

      </td> 
    </tr>
  </table>
</body>

</html>
